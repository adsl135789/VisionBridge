{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup and Configuration\n",
    "Install and import necessary libraries, such as `requests` and `json`. Define constants for the Gemini API key and endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# Install necessary libraries\n",
    "!pip install -q -U google-genai\n",
    "!pip install requests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "from google import genai\n",
    "\n",
    "# Define constants for the Gemini API key and endpoint\n",
    "GEMINI_API_KEY = \"AIzaSyAGxnOv00AxrOfIYbEs8oOZBQwYisZ5u2I\"  # Replace with your actual Gemini API key\n",
    "\n",
    "client = genai.Client(api_key=GEMINI_API_KEY)\n",
    "model = \"gemini-2.0-flash-exp-image-generation\"  # Specify the model you want to use\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upload and Read Image\n",
    "Write code to upload an image to the Gemini API and retrieve its metadata or content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload and Read Image\n",
    "import PIL.Image\n",
    "import json\n",
    "from google.genai import types\n",
    "\n",
    "\n",
    "# Function to upload an image to the Gemini API and retrieve its metadata or content\n",
    "def upload_and_read_image(image_path, user_prompt):\n",
    "    \"\"\"\n",
    "    Uploads an image to the Gemini API and retrieves its metadata or content based on the user prompt.\n",
    "\n",
    "    Args:\n",
    "        image_path (str): Path to the image file to be uploaded.\n",
    "        user_prompt (str): User prompt describing what to extract from the image.\n",
    "\n",
    "    Returns:\n",
    "        dict: Response from the Gemini API containing the image description or metadata.\n",
    "    \"\"\"\n",
    "    # Open the image file in binary mode\n",
    "    if image_path != \"\":\n",
    "        image = PIL.Image.open(image_path)\n",
    "        response = client.models.generate_content(\n",
    "            model=model,\n",
    "            contents=[user_prompt, image],\n",
    "            config=types.GenerateContentConfig(\n",
    "                temperature= 0,\n",
    "                response_mime_type= 'application/json'\n",
    "            ))\n",
    "                \n",
    "\n",
    "    \n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "import textwrap\n",
    "\n",
    "image_dir = \"image\"  # Replace with the actual path to your image\n",
    "image_name = [\"嘉義遊園地.png\", \"夏日街景.jpg\", \"淡水風景.png\", \"鳶尾花.jpg\", \"蒙娜麗莎的微笑.png\", \"星夜.png\"]\n",
    "image_path = f\"{image_dir}/{image_name[1]}\"\n",
    "# # 畫作資訊\n",
    "# - 畫作名稱: {}\n",
    "# - 創作者: {}\n",
    "# - 創作年份: {}\n",
    "# - 畫作風格: {}\n",
    "\n",
    "user_prompt = textwrap.dedent(\n",
    "\"\"\"\n",
    "請依照口述影像原則來描述這幅畫的內容，目標是要依照文字就能讓聽者想像此畫作。\n",
    "\n",
    "# 畫作描述\n",
    "## 口述影像原則\n",
    "- 描述應該是客觀的，避免主觀情緒或詮釋性用語。\n",
    "- 使用簡單明瞭的語言，避免使用專業術語或難懂的詞彙。\n",
    "- 描述的長度應該適中，既要詳細又不冗長，讓讀者能夠快速理解畫作的內容。\n",
    "- 提到畫面中的物件時，請用上、下、左、右、遠、近來描述該物件在畫面中的絕對位置。\n",
    "- 使用更具象化、可觸知的描述，用比喻與觸覺可想像的形容，讓讀者能夠在腦海中形成清晰的畫面。\n",
    "- 適度引導聽者想像畫面可能的場景或情境，但避免主觀臆測。\n",
    "    \n",
    "## 口述影像描述順序\n",
    "1. 完形與整體印象\n",
    "    - 先提供畫面的整體視覺印象，例如色調、構圖、氛圍等。\n",
    "    - 描述主要物件的位置關係、整體結構與視覺風格（如筆觸、材質感、光線等）。\n",
    "    - 可適度引導聽者想像畫面可能的場景或情境\n",
    "2. 區域與構成分析\n",
    "    - 將畫面劃分為數個區塊（如左／中／右、上／下、前景／背景），有邏輯地描述各區塊。\n",
    "    - 說明主體與背景、人物與物件、動靜對比、空間深度、顏色對比等結構特徵。\n",
    "3. 結語與情感總結\n",
    "    - 在結尾整理畫面的整體印象，重申主體與畫面特徵。\n",
    "    - 可指出畫面可能營造的情緒氛圍（如寧靜、壓迫、歡愉），但避免主觀臆測。\n",
    "    - 若畫面有敘事性，可引導「可能的事件」或「未說出口的情境」，例如：「彷彿畫中人正準備轉身離去」等。\n",
    "\n",
    "## 觀畫重點\n",
    "- 畫面的主題：畫作的主題是什麼？是人物、風景、靜物還是抽象？\n",
    "- 色彩與光線：畫面中使用了哪些顏色？是否有顏色上的對比？光線的來源和強度如何？\n",
    "- 筆觸與質感：筆觸是細膩柔和、光滑精緻，還是粗獷有力、充滿動感？\n",
    "- 人物的特徵：如果畫面中有人物，請描述它們的姿態、表情。\n",
    "\n",
    "# 畫作意境\n",
    "- 請用關鍵字來描述意境\n",
    "- 畫面給人的第一感覺是什麼？是寧靜的、壓抑的、歡快的、神祕的？\n",
    "\n",
    "# 畫作物件\n",
    "- 請列出畫面中的物件，並附上一種主要顏色就好。\n",
    "- 請使用常見的基本色系 \n",
    "- 格式：[\"實體\":\"顏色\"]，例如:[\"樹木\":\"綠色\"]，[\"天空\":\"藍色\"]\n",
    "\n",
    "# 要求\n",
    "- 請勿用不確定的口吻描述，不確定的細節不必提到\n",
    "- 請保留顏色的描述，例如「紅色的花朵」或「藍色的天空」，而不是「花朵」或「天空」。\n",
    "- 請直接輸出繁體中文的描述內容，不需要列點式描述，請用語意通順的一個段落描述畫面。\n",
    "- 請不要提到「觀者」等詞彙，請用第三人稱的方式描述畫面。\n",
    "- 請回傳JSON格式輸出，包含以下欄位：\n",
    "    1. \"description\": \"畫作描述\"\n",
    "    2. \"artistic_conception\" : \"畫作意境\"\n",
    "    3. \"object\": [\"實體\":\"顏色\"]\n",
    "\"\"\"\n",
    "\n",
    ")\n",
    "\n",
    "\n",
    "# Example usage\n",
    "result = upload_and_read_image(image_path, user_prompt)\n",
    "\n",
    "# Print the result\n",
    "print(result.text)\n",
    "\n",
    "cleaned_text = result.text.strip(\"`\").strip()\n",
    "lines = cleaned_text.splitlines()\n",
    "\n",
    "if lines[0].strip().lower() in ['json', '```json']:\n",
    "    lines = lines[1:]\n",
    "\n",
    "json_str = \"\\n\".join(lines)\n",
    "data = json.loads(json_str)\n",
    "for i in data[\"description\"].split(\"。\"):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 多輪對話：深入探索畫作細節\n",
    "\n",
    "這個部分讓你可以與模型進行多輪對話，詢問關於畫作的更多細節。模型會記住之前的對話歷史，讓你可以基於先前的回答繼續提問。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArtworkConversation:\n",
    "    def __init__(self, image_path, initial_data):\n",
    "        self.image_path = image_path\n",
    "        self.initial_data = initial_data\n",
    "        self.history = [\n",
    "            {\"role\": \"system\", \"content\": \"你是一個藝術評論專家，專門解析畫作細節。請基於畫面內容回答問題，避免臆測。請用繁體中文回答。\"},\n",
    "            {\"role\": \"assistant\", \"content\": f\"我已經分析了這幅畫作，以下是基本描述：\\n\\n{initial_data['description']}\\n\\n意境：{initial_data['artistic_conception']}\\n\\n你可以問我關於這幅畫的任何細節。\"}\n",
    "        ]\n",
    "        self.image = PIL.Image.open(image_path)\n",
    "    \n",
    "    def ask(self, question):\n",
    "        \"\"\"向模型提問，並記錄對話歷史\"\"\"\n",
    "        # 添加用戶問題到歷史記錄\n",
    "        self.history.append({\"role\": \"user\", \"content\": question})\n",
    "        \n",
    "        # 構建提示\n",
    "        context_prompt = f\"\"\"基於我們之前的對話和畫作圖像，請回答我的問題。請只回答與畫作直接相關的內容，如果無法從畫面中判斷，請誠實說明。\n",
    "        以下是我們之前的對話歷史摘要：\n",
    "        \n",
    "        {self.history[-1]['content']}\n",
    "        \n",
    "        我的問題是：{question}\"\"\"\n",
    "        print(context_prompt)\n",
    "        try:\n",
    "            # 調用API - 修改內容結構以解決驗證錯誤\n",
    "            response = client.models.generate_content(\n",
    "                model=model,\n",
    "                contents=[context_prompt, self.image],  # 簡化內容結構\n",
    "                config=types.GenerateContentConfig(\n",
    "                    temperature=0.2\n",
    "                )\n",
    "            )\n",
    "            \n",
    "            # 記錄模型回答\n",
    "            answer = response.text\n",
    "            self.history.append({\"role\": \"assistant\", \"content\": answer})\n",
    "            \n",
    "            return answer\n",
    "        except Exception as e:\n",
    "            print(f\"發生錯誤: {str(e)}\")\n",
    "            return f\"處理請求時發生錯誤: {str(e)}\"\n",
    "    \n",
    "    def get_history(self):\n",
    "        \"\"\"獲取對話歷史\"\"\"\n",
    "        return self.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32d0c871f4224fdfbc13e7eae9e5d14e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='<h3>與畫作對話</h3>')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b198bd0966443b99b3721f1ac444ec0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "# 檢查是否已經分析過畫作\n",
    "if 'data' in locals() and 'image_path' in locals():\n",
    "    # 初始化對話\n",
    "    conversation = ArtworkConversation(image_path, data)\n",
    "    \n",
    "    # 創建UI元素\n",
    "    conversation_output = widgets.Output()\n",
    "    \n",
    "    # 顯示UI\n",
    "    display(widgets.HTML(\"<h3>與畫作對話</h3>\"))\n",
    "    display(conversation_output)\n",
    "    \n",
    "    # 提示使用者可以開始提問\n",
    "    with conversation_output:\n",
    "        print(\"可以問的問題範例：\")\n",
    "        examples = [\n",
    "            \"畫面中最前景的主要物件有哪些？\",\n",
    "            \"這幅畫的光影效果如何？光源從哪個方向照射？\",\n",
    "            \"畫中有哪些細節可能容易被忽略？\",\n",
    "            \"畫面中的色彩搭配有什麼特色？\",\n",
    "            \"這幅畫的構圖方式是什麼？重心在哪裡？\"\n",
    "        ]\n",
    "        for ex in examples:\n",
    "            print(f\"- {ex}\")\n",
    "        print(\"\\n你可以開始提問了！輸入「結束」來結束對話。\\n\")\n",
    "    \n",
    "    # 使用 while 迴圈進行提問\n",
    "    while True:\n",
    "        question = input(\"請輸入問題（輸入「結束」以結束對話）：\").strip()\n",
    "        if question == \"結束\":\n",
    "            with conversation_output:\n",
    "                print(\"\\n對話已結束。感謝您的使用！\")\n",
    "            break\n",
    "        elif question:\n",
    "            with conversation_output:\n",
    "                # 顯示用戶問題\n",
    "                print(f\"\\033[1m\\033[94m問題: {question}\\033[0m\")\n",
    "                \n",
    "                # 獲取回答\n",
    "                answer = conversation.ask(question)\n",
    "                \n",
    "                # 顯示回答\n",
    "                print(f\"\\033[1m\\033[92m回答:\\033[0m {answer}\\n\")\n",
    "        else:\n",
    "            with conversation_output:\n",
    "                print(\"請輸入有效的問題。\")\n",
    "else:\n",
    "    print(\"請先執行上面的代碼以獲取畫作的基本描述，然後再使用對話功能。\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 查看完整對話歷史\n",
    "\n",
    "如果你想查看或保存整個對話過程，可以執行下面的代碼來顯示完整對話歷史。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# 顯示完整對話歷史\n",
    "if 'conversation' in locals():\n",
    "    history = conversation.get_history()\n",
    "    # 跳過系統提示\n",
    "    for i, entry in enumerate(history):\n",
    "        if i == 0 and entry['role'] == 'system':  # 跳過系統提示\n",
    "            continue\n",
    "            \n",
    "        role = entry['role']\n",
    "        content = entry['content']\n",
    "        \n",
    "        if role == 'user':\n",
    "            print(f\"\\033[1m\\033[94m用戶: {content}\\033[0m\\n\")\n",
    "        elif role == 'assistant':\n",
    "            print(f\"\\033[1m\\033[92m助理: {content}\\033[0m\\n\")\n",
    "        print(\"-\" * 80)\n",
    "else:\n",
    "    print(\"尚未開始對話，請先使用上方的對話功能。\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
